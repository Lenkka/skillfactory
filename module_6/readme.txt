## Выводы

Достигнутая в соревновании максимальная метрика: 12.51618

I. Основные цели и задачи проекта

Суть учебного проекта — предсказать цену на автомобиль среди тех машин, которые продает компания.

Цель проекта - собрать данные или воспользоваться готовыми, привести их в пригодный для обучения модели вид, сгенерировать новые признаки. Затем обучить модель на тренировочных данных и применить на тестовых.

Задачи проекта: очистить данные, провести их оценку и преобразование. Создать новые данные. Построить и обучить модель. "Скормить" модели тестовые данные и получить результат: цену автомобиля.

Учебные задачи проекта: применить на практике изученное в пройденных модулях курса.

Основная метрика проекта: MAPE - средняя абсолютная ошибка.

II. Краткая информация о данных

Данные были предоставлены в отличном от тестовых виде - с другим набором колонок, большим количеством пропусков и небольшим количеством выбросов.

III. Этапы работы над проектом
0. Забеспокоиться, что ничего не успеваю и ничего не выйдет.
1. Составить план анализа (применен pandas.profiling), оценить данные и сделать выводы. 
   Ссылка на ноутбук с результатами: https://www.kaggle.com/lenkavinogradova/pandas-profiling-for-car-selection
2. Привести данные (трэйн и тест) к единообразию по признакам, очистить данные и заполнить пропуски.
3. Отобрать данные, которые влияют на конечный результат.
4. Преобразовать данные в вид, пригодный для модели.
5. Создать новые признаки на основе имеющихся данных.
6. Построить наивную модель, обучить ее.
7. Улучшить наивную модель.
8. Применить еще несколько вариантов моделей, в том числе stacking и bagging.
9. Протестировать финальную модель на тестовых данных и сформировать файл-результат. 
10. Принять участие в соревновании.

Хотя работа подразумевала командный подход, мне пришлось делать все в одиночку (вот уже третий проект не получается набрать команду). 

IV. Особенности работы
Не хватило времени и сил на написание собственного парсинга, а при попытке воспользоваться результатом программы парсинга - на приведение в соответствие внутренних и внешних результатов (https://www.kaggle.com/lenkavinogradova/proba-car-selection-2a)
Наивная модель оказалась очень слабо отличающейся (но в лучшую сторону) от той, которая была в базовом решении. 
Лучшей моделью оказалась XGB Regressor, но в бэггинге она не улучшилась.
Некоторые модели обучаются очень долго, и приходилось запускать их по одной, что не упростило задачу.


V. Что можно было сделать лучше:

1. Больше уделить внимание признакам. Например, не только сочинять признаки на основании уже имеющихся, но и взять временные признаки на основе времени парсинга объявления - например, коэффициент по курсу доллара или евро. Или создать векторы описаний и использовать их как признак.
2. Более подробно проанализировать признаки (точнее, записать полнее результаты обдумывания).
3. Лучше применять инструменты подбора гиперпараметров и не жалеть на это времени.
4. Поиграть с нормализацией и стандартизацией данных.
5. Найти еще интересные модели обучения.
6. Побольше поработать над обоснованиями решения и больше опираться на теоретическую часть курса.
7. Все-таки найти кого-то в команду, а не разрываться на тысячу частей.


VI. Что мне удалось
1. Код аккуратный и достаточно полно прокомментированный.
2. Рабочие модели показывают неплохой результат, не слишком удаленный от окончательного (на тестовых данных).
2. Некоторые вещи, которые в теории были непонятными, на практике прояснились.

Вывод: Мне очень нравится создавать новые признаки и обрабатывать старые, но для сравнения моделей (и подбора параметров) не хватает терпения. Нужен компьютер посильнее :)
