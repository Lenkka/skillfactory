Car Price prediction
Прогнозирование стоимости автомобиля по характеристикам
В этом задании нужно спрогнозировать, сколько будет стоить автомобиль. Учебное задание:
провести анализ данных;
построить модели и подать в них правильные данные
обработать изображения и текстовые описания для корректной работы с моделью.

Работа выполнена студенткой группы 24 курса "Профессия Data Scientist" Еленой Виноградовой. Ник на Kaggle: Lenka Vinogradova (https://www.kaggle.com/lenkavinogradova)
Самый высокий score при сабмите: 11.28506

Описание работы и учебные выводы:

В этой работе основная задача пришлась на подготовку, анализ и обработку данных. Сделано описание признаков, работа снабжена комментариями. 
Целевая переменная исследована в отдельном ноутбуке (https://github.com/Lenkka/skillfactory/blob/master/module_7/pandas-profiling-1-for-car-selection-part-2.ipynb). 
Для еще более удачного результата target для catboost можно было бы логарифмировать.

Для каждой модели данные подаются отдельно (состав признаков, обработка), что позволяет достичь лучших результатов. 
Для поля "Описание" была проведена лемматизация и частичная очистка от служебных слов. 
Для изображений приведена аугментация на основе приведенного примера (дополнен новыми фичами). 

Были изменена структура первой нейросети (для табличных данных). 
К сожалению, применение этого решения в дальнейшем сильно тормозило обучение и не сказывалось на результате в положительную сторону.

Блендирование показало достаточно хорошие результаты как на тестовых, так и на живых данных.

В отдельных ноутбуках проведены эксперименты с другими моделями: xb - результат на тесте недостаточно хорош, catboost умеет лучше. 
На LightAutoML (тестовая MAPE 11.52) не хватило ускорителя.

Лучших результатов можно было достичь за счет более тонкого подбора и очистки данных, тщательной очистки и дополнительной обработки признака description, 
дополнительной аугментации картинок и более пристального внимания к структуре нейросети. Также не освоила fine tuning.

В этой версии нейросеть с обработкой изображений склонна к переобучению, и я не успела понять, почему так происходит.

Выводы личного характера: 
1. Мне больше нравится готовить данные и скармливать их модели, чем изменять саму модель. Видимо, с данными я уже более-менее освоилась, а модели пока еще вызывают опасение. 
2. Очень нервируют ограничения по GPU - но такова жизнь. Никто машинного времени больше, чем есть, не даст. 
3. Нужно тщательнее повторить про сохранение модели и load_weight, а также про структуру нейросети. 
4. Если меньше нервничать и спокойнее относиться к периодам, когда модель учится, а ты нет - работа будет только эффективнее.
