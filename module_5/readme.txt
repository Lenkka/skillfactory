Описание проекта:

I. Основные цели и задачи проекта

Суть учебного проекта — найти среди будущих заемщиков тех, кому кредит давать нежелательно (велика вероятность дефолта).

Целью проекта было привести данные в пригодный для обучения модели вид, обучить модель на тренировочных данных и применить на тестовых.

Задачи проекта: очистить данные, провести их оценку и преобразование. Построить и обучить модель. "Скормить" модели тестовые данные и получить результат: вероятность дефолта заемщика.

Учебные задачи проекта: применить на практике изученное в пройденных модулях курса.

II. Краткая информация о данных

Данные были предоставлены в достаточно полном виде с минимумом пропусков и небольшим количеством выбросов.

III. Этапы работы над проектом

1. Выполнить вспомогательные задания и сделать выводы
2. Составить план анализа (применен pandas.profiling), оценить данные и сделать выводы. 
   Ссылка на ноутбук с результатами и выводами https://www.kaggle.com/lenkavinogradova/sf-dst-credit-scoring-profiling-vinogradova
3. Заполнить пропуски и минимизировать выбросы.
4. Отобрать данные, которые влияют на конечный результат.
5. Преобразовать данные в вид, пригодный для модели.
6. Создать новые признаки на основе имеющихся данных.
7. Построить модель, обучить ее.
8. Улучшить модель.
9. Протестировать финальную модель на тестовых данных и сформировать файл-результат. 
10. Принять участие в соревновании.

Хотя работа подразумевала командный подход, я решила выполнять ее в одиночку. Основной трудностью считаю нехватку времени (в команде было бы легче, 
но набор команды требует времени - замкнутый круг). 

IV. Особенности работы
Сразу наступила на грабли с округлением - поняла ошибку после первого сабмита
Метрика ROC AUC оказалась внезапно отличной - но не оценка качества файла при сабмите. Применила матрицу ошибок - поняла, что происходит.
Первая модель оказалась переобученной, пришлось применить oversampling (то есть создать копии меньшего класса (есть дефолт), чтобы сравнять его размер с большим классом (нет дефолта).
Модель снизила метрику ROC AUC, зато повысились true positive значения в матрице ошибок и метрика F1-score тоже подросла.

Гиперпараметры я подбирала руками, и это непродуктивный путь. Но теперь модель стала работать немного лучше.

V. Что можно было сделать лучше:
1. Больше уделить внимание признакам (например, связям с другими клиентами банка)
2. Освоить инструменты подбора гиперпараметров
3. Посмотреть другие модели обучения и сравнить, как от типа модели зависит результат.
4. Все-таки найти кого-то в команду, а не разрываться на тысячу частей.

Вывод: не все я понимаю четко, кое-где не очень могу объяснить, почему это должно работать, но какой-то результат получился: score 0.73910 в соревновании кажется не слишком плохим.
Возможно, конечно, дело в том, что я просто хороший педагог*?

* я по диплому преподаватель :)
